{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b194fab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dc9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, TrainerConfig\n",
    "from models import BaselineModel\n",
    "from dataset import DocumentDataset, get_train_val_dataset\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d014781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel()\n",
    "config = TrainerConfig()\n",
    "config.epochs = 10\n",
    "train_dataset, val_dataset = get_train_val_dataset('dataset/train.json', max_instances=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb4ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_trainer = Trainer(model, config, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88dd466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpotemin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15f7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_config_to_dict(train_config: TrainerConfig):\n",
    "    return dict((name, getattr(train_config, name)) for name in dir(train_config) if not name.startswith('__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e95eb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Kontur\", config=train_config_to_dict(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ca63990",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 0 | train_loss: 6.63838: 100%|███████| 1/1 [00:03<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 6.638383865356445, epoch: 1\n",
      "epoch 0: {'exact_match': 0.0, 'f1': 8.005006257822277, 'val_loss': 6.170821666717529, '_timestamp': 1680963937, '_runtime': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 iter 0 | train_loss: 6.29380: 100%|███████| 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 6.293797492980957, epoch: 2\n",
      "epoch 1: {'exact_match': 25.0, 'f1': 52.58692545844248, 'val_loss': 5.976446151733398, '_timestamp': 1680963940, '_runtime': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 iter 0 | train_loss: 5.98731: 100%|███████| 1/1 [00:02<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 5.987307071685791, epoch: 3\n",
      "epoch 2: {'exact_match': 25.0, 'f1': 53.94736842105263, 'val_loss': 5.792342185974121, '_timestamp': 1680963944, '_runtime': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 iter 0 | train_loss: 5.69536: 100%|███████| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 5.695362091064453, epoch: 4\n",
      "epoch 3: {'exact_match': 25.0, 'f1': 53.94736842105263, 'val_loss': 5.610640525817871, '_timestamp': 1680963947, '_runtime': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 iter 0 | train_loss: 5.40691: 100%|███████| 1/1 [00:03<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 5.406907081604004, epoch: 5\n",
      "epoch 4: {'exact_match': 25.0, 'f1': 54.07268170426065, 'val_loss': 5.426244258880615, '_timestamp': 1680963951, '_runtime': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 iter 0 | train_loss: 5.12021: 100%|███████| 1/1 [00:02<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 5.120213985443115, epoch: 6\n",
      "epoch 5: {'exact_match': 25.0, 'f1': 54.07268170426065, 'val_loss': 5.237765312194824, '_timestamp': 1680963954, '_runtime': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 iter 0 | train_loss: 4.83434: 100%|███████| 1/1 [00:02<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.834342002868652, epoch: 7\n",
      "epoch 6: {'exact_match': 25.0, 'f1': 48.80952380952381, 'val_loss': 5.047122955322266, '_timestamp': 1680963957, '_runtime': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 iter 0 | train_loss: 4.54623: 100%|███████| 1/1 [00:02<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.546230792999268, epoch: 8\n",
      "epoch 7: {'exact_match': 25.0, 'f1': 48.80952380952381, 'val_loss': 4.857145309448242, '_timestamp': 1680963960, '_runtime': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 iter 0 | train_loss: 4.25414: 100%|███████| 1/1 [00:02<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 4.2541399002075195, epoch: 9\n",
      "epoch 8: {'exact_match': 25.0, 'f1': 48.80952380952381, 'val_loss': 4.670167446136475, '_timestamp': 1680963963, '_runtime': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 iter 0 | train_loss: 3.96199: 100%|██████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 3.96199107170105, epoch: 10\n",
      "epoch 9: {'exact_match': 25.0, 'f1': 48.80952380952381, 'val_loss': 4.488231658935547, '_timestamp': 1680963967, '_runtime': 36}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>exact_match</td><td>▁█████████</td></tr><tr><td>f1</td><td>▁█████▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▄▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>exact_match</td><td>25.0</td></tr><tr><td>f1</td><td>48.80952</td></tr><tr><td>train_loss</td><td>3.96199</td></tr><tr><td>val_loss</td><td>4.48823</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sunny-star-5</strong>: <a href=\"https://wandb.ai/potemin/Kontur/runs/3my066b2\" target=\"_blank\">https://wandb.ai/potemin/Kontur/runs/3my066b2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230408_212526-3my066b2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
